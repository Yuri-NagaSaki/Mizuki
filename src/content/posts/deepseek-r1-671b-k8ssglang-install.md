---
title: "DeepSeek-r1:671bæ»¡è¡€ç‰ˆåœ¨K8S+SGLangæ¶æ„ä¸‹çš„å¤šèŠ‚ç‚¹GPUç§æœ‰åŒ–å®è·µ"
published: 2025-02-19
categories: 
  - "llm"
  - "laboratory"
coverImage: "image-10.png"
---

## åº”ç”¨å‰æ™¯

**éšç€DeepSeek-r1åƒäº¿çº§å¤§æ¨¡å‹åœ¨ä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†ç­‰å¤æ‚ä»»åŠ¡ä¸­çš„çªç ´æ€§è¡¨ç°ï¼Œä¼ä¸šçº§ç§æœ‰åŒ–éƒ¨ç½²éœ€æ±‚å‘ˆç°æŒ‡æ•°çº§å¢é•¿ã€‚å½“å‰å¸‚åœºä¸­ï¼ŒOllamaå‡­å€Ÿè½»é‡åŒ–æ¶æ„å’Œè·¨å¹³å°å…¼å®¹æ€§ï¼ˆæ”¯æŒNVIDIA/AMDå…¨ç³»GPUåŠä¸»æµå¤§æ¨¡å‹æ ¼å¼ï¼‰ï¼Œä¸ºå¼€å‘è€…æä¾›äº†å¼€ç®±å³ç”¨çš„æœ¬åœ°è°ƒè¯•æ–¹æ¡ˆã€‚ä½†å…¶å•èŠ‚ç‚¹æ¶æ„ä¸æœ´ç´ çš„è°ƒåº¦ç­–ç•¥ï¼Œåœ¨é¢å¯¹ç”Ÿäº§çº§é«˜å¹¶å‘æ¨ç†åœºæ™¯æ—¶ï¼Œååé‡ç›¸è¾ƒvLLMã€SGLangç­‰ä¸“ç”¨æ¨ç†æ¡†æ¶å­˜åœ¨30%ä»¥ä¸Šçš„æ€§èƒ½é¸¿æ²Ÿã€‚**

## è§£å†³æ–¹æ¡ˆ

æœ¬æ–‡å°†ä»¥DeepSeek-r1-671bæ»¡è¡€ç‰ˆä¸ºåŸºå‡†æ¨¡å‹ï¼Œæ·±å…¥è§£æåŸºäºKubernetes+SGLangçš„äº‘åŸç”Ÿæ¨ç†åŠ é€Ÿæ¶æ„ã€‚é€šè¿‡èåˆLeaderWorkerSetæ§åˆ¶å™¨å®ç°åˆ†å¸ƒå¼ä»»åŠ¡ç¼–æ’ã€Volcanoæ‰¹é‡è°ƒåº¦ç³»ç»Ÿå¼ºåŒ–GPUèµ„æºæŠ¢å å¼åˆ†é…ï¼Œæ„å»ºå…·å¤‡ä»¥ä¸‹ç‰¹æ€§çš„ä¼ä¸šçº§éƒ¨ç½²æ–¹æ¡ˆï¼š

1. **æ€§èƒ½è·ƒè¿**ï¼šåŸºäºSGLangçš„RadixAttentionæ ¸å¿ƒæŠ€æœ¯ï¼Œå®ç°KV Cacheå¤ç”¨ç‡æå‡60%+

3. **å¼¹æ€§æ‹“æ‰‘**ï¼šæ”¯æŒMulti-Node Multi-GPUçš„åŠ¨æ€æ‰©ç¼©å®¹ç­–ç•¥ï¼ˆH100/A100å¼‚æ„é›†ç¾¤å…¼å®¹ï¼‰

5. **ç”Ÿäº§å°±ç»ª**ï¼šé›†æˆPrometheus+Grafanaçš„å®æ—¶æ¨ç†ç›‘æ§ä½“ç³»ï¼ŒTP99å»¶è¿Ÿå¯æ§åœ¨200mså†…

## **é€‰å‹SGLangæ¨ç†å¼•æ“çš„ç†ç”±**

### **SGLang vs Ollama å…³é”®èƒ½åŠ›å¯¹æ¯”çŸ©é˜µ**

| **èƒ½åŠ›ç»´åº¦** | **SGLang (ç”Ÿäº§çº§å¼•æ“)** | **Ollama (å¼€å‘çº§å·¥å…·)** |
| --- | --- | --- |
| **æ¶æ„è®¾è®¡** | âœ… åˆ†å¸ƒå¼æ¨ç†æ¶æ„   ï¼ˆå¤šæœºå¤šå¡ååŒï¼‰ | âŒ å•èŠ‚ç‚¹è¿è¡Œ   ï¼ˆä»…é™æœ¬åœ°GPUï¼‰ |
| **æ€§èƒ½è¡¨ç°** | ğŸ”¥ ååé‡æå‡300%+   ï¼ˆRadixAttentionä¼˜åŒ–ï¼‰ | â³ é€‚åˆä½å¹¶å‘åœºæ™¯   ï¼ˆæœ´ç´ è°ƒåº¦ç­–ç•¥ï¼‰ |
| **ç”Ÿäº§å°±ç»ªæ€§** | ğŸ“Š å†…ç½®Prometheusç›‘æ§+ç†”æ–­é™çº§æœºåˆ¶ | âŒ æ— ç›‘æ§/é«˜å¯ç”¨ä¿éšœ |
| **æ‰©å±•èƒ½åŠ›** | âš¡ åŠ¨æ€æ‰©ç¼©å®¹+å¼‚æ„é›†ç¾¤ç®¡ç†   ï¼ˆK8s/Volcanoé›†æˆï¼‰ | âŒ å›ºå®šèµ„æºé…ç½®   ï¼ˆæ— é›†ç¾¤æ”¯æŒï¼‰ |
| **ä¼ä¸šç‰¹æ€§** | ğŸ”’ å•†ä¸šSLAæ”¯æŒ+å®šåˆ¶åŒ–OPå¼€å‘ | âŒ ä»…ç¤¾åŒºç‰ˆç»´æŠ¤ |
| **é€‚ç”¨åœºæ™¯** | åƒäº¿çº§æ¨¡å‹ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²   ï¼ˆç”µå•†/é‡‘èç­‰é«˜å¹¶å‘åœºæ™¯ï¼‰ | ä¸ªäººå¼€å‘è€…æœ¬åœ°è°ƒè¯•   ï¼ˆå°æ¨¡å‹å¿«é€ŸéªŒè¯ï¼‰ |

* * *

### **ä¸ºä»€ä¹ˆé€‰æ‹©SGLangï¼Ÿ**

1. **æ€§èƒ½ç¢¾å‹**
    - **Ollamaå•å¡QPSâ‰¤20ï¼ŒSGLangåˆ†å¸ƒå¼é›†ç¾¤QPSâ‰¥200ï¼ˆ10å€æå‡ï¼‰**
    
    - **åœ¨32ké•¿æ–‡æœ¬åœºæ™¯ï¼ŒSGLangæ¨ç†å»¶è¿Ÿç¨³å®šåœ¨300mså†…ï¼ŒOllamaé¢‘ç¹è§¦å‘OOM**

3. **æˆæœ¬ä¼˜åŠ¿**
    - **é€šè¿‡KV Cacheå¤ç”¨ï¼Œé›†ç¾¤èµ„æºåˆ©ç”¨ç‡è¾¾85%+ï¼ˆOllamaä»…40%-50%ï¼‰**
    
    - **æ”¯æŒFP8é‡åŒ–å‹ç¼©ï¼Œç›¸åŒååé‡ä¸‹ç¡¬ä»¶æˆæœ¬é™ä½60%**

5. **é£é™©æ§åˆ¶**
    - **Ollamaæ— ç†”æ–­/é™çº§æœºåˆ¶ï¼Œçªå‘æµé‡æ˜“å¯¼è‡´æœåŠ¡é›ªå´©**
    
    - **SGLangå†…ç½®åˆ†çº§æµé‡ç®¡æ§ï¼Œä¿éšœæ ¸å¿ƒä¸šåŠ¡SLAä¸ä¸­æ–­**

* * *

**å†³ç­–å»ºè®®**ï¼š

- **é€‰SGLangï¼šå½“æ‚¨éœ€è¦Â æ”¯æ’‘çº¿ä¸Šç”Ÿäº§æµé‡ã€å¤„ç†ç™¾äº¿çº§ä»¥ä¸Šå‚æ•°æ¨¡å‹ã€å®ç°èµ„æºé›†çº¦åŒ–åˆ©ç”¨**

- **é€‰Ollamaï¼šä»…ç”¨äºÂ ä¸ªäººå­¦ä¹ ç ”ç©¶ã€å°æ¨¡å‹å¿«é€ŸéªŒè¯ã€æ— SLAè¦æ±‚çš„æœ¬åœ°æµ‹è¯•**

**é€šè¿‡æ¶æ„çº§ä¼˜åŒ–ä¸ç”Ÿäº§å¢å¼ºè®¾è®¡ï¼ŒSGLangåœ¨æ€§èƒ½ã€ç¨³å®šæ€§ã€æ‰©å±•æ€§ç­‰ç»´åº¦å®ç°å¯¹Ollamaçš„ä»£é™…å·®è·çº§è¶…è¶Šã€‚**

## ç¯å¢ƒå‡†å¤‡

æœ¬æ¬¡éƒ¨ç½²çš„ä¸ºæ»¡è¡€ç‰ˆ DeepSeek-r1:671b

**ç¡¬ä»¶é…ç½®**

| æœåŠ¡å™¨ | æ•°é‡ï¼ˆå°ï¼‰ | CPUï¼ˆæ ¸ï¼‰ | å†…å­˜ï¼ˆTBï¼‰ | ç³»ç»Ÿç‰ˆæœ¬ |
| --- | --- | --- | --- | --- |
| NVIDIA A800 80GB | 2 | 128 | 2 | Ubuntu 22.04.5 LTS |

> **è½¯ä»¶å¹³å°**
> 
> | è½¯ä»¶åç§° | ç‰ˆæœ¬ | å¤‡æ³¨ |
> | --- | --- | --- |
> | Kubernetes | v1.30.6 | å®¹å™¨ç¼–æ’å¼•æ“ |
> | GPU Operator | v24.9.1 | è‡ªåŠ¨åŒ–ç®¡ç†é…ç½®GPUé©±åŠ¨ç¨‹åº |
> | Volcano | v1.9.0 | è°ƒåº¦å¼•æ“ |
> | NVIDIA Driver | 550.127.05 | GPUé©±åŠ¨ |
> | NVIDIA-Fabric Manager | 550.127.05 | NVSwitchäº’è” |
> | CUDA | 12.4 | Cuda |
> | MLNX\_OFED | 24.10-0.7.0.0 | IBé©±åŠ¨ |
> | NCCL | 2.21.5 | GPUå¤šå¡é€šä¿¡ |
> | SGLang | v0.4.3.post2-cu124 | LLMæ¨ç†å¼•æ“ |
> | LeaderWorkerSet | v0.5.1 | PodGroup Deploy API |
> | open-webui | v0.5.14 | AIèŠå¤©äº’åŠ¨å·¥å…· |
> 
> ### æ¨¡å‹å‡†å¤‡
> 
> æ–¹å¼ä¸€ï¼šé€šè¿‡`HuggingFace`Â ä¸‹è½½  
> ä»“åº“åœ°å€ï¼šhttps://huggingface.co/deepseek-ai/DeepSeek-R1

> æ–¹å¼äºŒï¼šé€šè¿‡Â `ModelScope`Â ä¸‹è½½ ï¼ˆå›½å†…æ¨èç”¨è¿™ä¸ªï¼‰  
> ä»“åº“åœ°å€ï¼šhttps://modelscope.cn/models/deepseek-ai/DeepSeek-R1/files

```shell
1ã€å®‰è£…ModelScope
pip3 install modelscope 

2ã€ä¸‹è½½å®Œæ•´æ¨¡å‹repo
mkdir /mnt/catcat_data/model/DeepSeek-R1 -p
nohup modelscope download --model deepseek-ai/DeepSeek-R1 --local_dir /mnt/catcat_data/model/DeepSeek-R1 &
```

<picture>
    <source srcset="https://s3.catcat.blog/images/2025/02/image-9.avif" type="image/avif">
    <source srcset="https://s3.catcat.blog/images/2025/02/image-9.webp" type="image/webp">
    <img src="https://s3.catcat.blog/images/2025/02/image-9.jpg" alt="" loading="lazy">
</picture>

å®æµ‹æ»¡è¡€æ¨¡å‹åœ¨Linuxä¸º642G.

## éƒ¨ç½²

### éƒ¨ç½²LWS API

**Githubé¡¹ç›®åœ°å€ï¼š**[https://github.com/kubernetes-sigs/lws](https://github.com/kubernetes-sigs/lws)

<picture>
    <source srcset="https://s3.catcat.blog/images/2025/02/image-10.avif" type="image/avif">
    <source srcset="https://s3.catcat.blog/images/2025/02/image-10.webp" type="image/webp">
    <img src="https://s3.catcat.blog/images/2025/02/image-10.jpg" alt="" loading="lazy">
</picture>

ä½¿ç”¨ LWS API çš„ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬ï¼š

- **ç®€åŒ–åˆ†å¸ƒå¼æ¨ç†çš„éƒ¨ç½²**Â ï¼šé€šè¿‡ LWS APIï¼Œæä¾›äº†ä¸€ä¸ªå£°æ˜å¼çš„ APIï¼Œç”¨æˆ·åªéœ€å®šä¹‰ Leader å’Œ Worker çš„é…ç½®ï¼ŒKubernetes æ§åˆ¶å™¨ä¼šè‡ªåŠ¨å¤„ç†å…¶ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚ç”¨æˆ·å¯ä»¥æ›´è½»æ¾åœ°éƒ¨ç½²å¤æ‚çš„åˆ†å¸ƒå¼æ¨ç†å·¥ä½œè´Ÿè½½ï¼Œè€Œæ— éœ€æ‰‹åŠ¨ç®¡ç† Leader å’Œ Worker çš„ä¾èµ–å…³ç³»å’Œå‰¯æœ¬æ•°é‡;

- **æ— ç¼æ°´å¹³æ‰©å®¹**Â ï¼š ä¸Šæ–‡ä¸­æåˆ°åˆ†å¸ƒå¼æ¨ç†çš„æœåŠ¡éœ€è¦å¤šä¸ªPOD å…±åŒæä¾›æœåŠ¡ï¼Œåœ¨è¿›è¡Œæ‰©å®¹æ—¶ä¹Ÿéœ€è¦ä»¥å¤šä¸ªPod ä¸€ç»„ä¸ºåŸå­å•ä½è¿›è¡Œæ‰©å±•ï¼Œ LWS å¯ä»¥ä¸ k8s HPA æ— ç¼å¯¹æ¥ï¼Œå°† LWS ä½œä¸ºHPA æ‰©å®¹çš„Targetï¼Œå®ç°æ¨ç†æœåŠ¡æ•´ç»„æ‰©å®¹;

- **æ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦**Â ï¼š åœ¨åˆ†å¸ƒå¼æ¨ç†ä¸­ï¼Œä¸åŒ Pod éœ€è¦è¿›è¡Œå¤§é‡æ•°æ®äº¤äº’ã€‚ ä¸ºäº†å‡å°‘é€šä¿¡å»¶æ—¶ LWS API ç»“åˆäº†æ‹“æ‰‘æ„ŸçŸ¥è°ƒåº¦ï¼Œä¿è¯èƒ½å¤Ÿä¿è¯ Leader å’Œ Worker Pod èƒ½å¤Ÿè°ƒåº¦åˆ° RDMA ç½‘ç»œä¸­æ‹“æ‰‘è·ç¦»å°½å¯èƒ½æ¥è¿‘çš„èŠ‚ç‚¹ä¸Šã€‚

<picture>
    <source srcset="https://s3.catcat.blog/images/2025/02/image-11.avif" type="image/avif">
    <source srcset="https://s3.catcat.blog/images/2025/02/image-11.webp" type="image/webp">
    <img src="https://s3.catcat.blog/images/2025/02/image-11.jpg" alt="" loading="lazy">
</picture>

```shell
å®‰è£… LWS API çš„ CRD
VERSION=v0.5.1
kubectl apply --server-side -f https://github.com/kubernetes-sigs/lws">https://github.com/kubernetes-sigs/lws/releases/download/$VERSION/manifests.yaml

æ£€æŸ¥LWS èµ„æº
kubectl get pods -n lws-system 
kubectl get svc -n lws-system
kubectl api-resources |grep -i lws

```

## éƒ¨ç½²DeepSeek-R1

```shell
apiVersion: leaderworkerset.x-k8s.io/v1
kind: LeaderWorkerSet
metadata:
  name: sglang
  labels:
    app: sglang
spec:
  replicas: 1
  startupPolicy: LeaderCreated
  rolloutStrategy:
    type: RollingUpdate
    rollingUpdateConfiguration:
      maxSurge: 0
      maxUnavailable: 2
  leaderWorkerTemplate:
    size: 2
    restartPolicy: RecreateGroupOnPodRestart
    leaderTemplate:
      metadata:
        labels:
          role: leader
      spec:
        containers:
          - name: sglang-head
            image: lmsysorg/sglang:v0.4.3.post2-cu124
            imagePullPolicy: IfNotPresent
            workingDir: /sgl-workspace
            command: ["sh", "-c"]
            args:
            - >
              cd /sgl-workspace && python3 -m sglang.launch_server
              --model-path /mnt/catcat_data/model/DeepSeek-R1
              --served-model-name deepseek-r1
              --tp 16
              --dist-init-addr $LWS_LEADER_ADDRESS:20000
              --nnodes $LWS_GROUP_SIZE
              --node-rank 0
              --trust-remote-code
              --context-length 131072
              --enable-metrics
              --host 0.0.0.0
              --port 8000
            env:
              - name: GLOO_SOCKET_IFNAME
                value: eth0
              - name: NCCL_IB_HCA
                value: "mlx5_0,mlx5_1,mlx5_4,mlx5_5"
              - name: NCCL_P2P_LEVEL
                value: "NVL"
              - name: NCCL_IB_GID_INDEX
                value: "0"
              - name: NCCL_IB_CUDA_SUPPORT
                value: "1"
              - name: NCCL_IB_DISABLE
                value: "0"
              - name: NCCL_SOCKET_IFNAME
                value: "eth0"
              - name: NCCL_DEBUG
                value: "INFO"
              - name: NCCL_NET_GDR_LEVEL
                value: "2"
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: SGLANG_USE_MODELSCOPE
                value: "true"
            ports:
            - containerPort: 8000
              name: http
              protocol: TCP
            - containerPort: 20000
              name: distributed
              protocol: TCP
            resources:
              limits:
                cpu: "128"
                memory: "1Ti"
                nvidia.com/gpu: "8"
                rdma/ib: "4"
              requests:
                cpu: "128"
                memory: "1Ti"
                nvidia.com/gpu: "8"
                rdma/ib: "4"
            securityContext:
              capabilities:
                add:
                - IPC_LOCK
                - SYS_PTRACE
            volumeMounts:
              - mountPath: /mnt/catcat_data/model
                name: model-volume
              - mountPath: /dev/shm
                name: shm-volume
              - name: localtime
                mountPath: /etc/localtime
                readOnly: true
            readinessProbe:
              tcpSocket:
                port: 8000
              initialDelaySeconds: 120
              periodSeconds: 30
        volumes:
          - name: model-volume
            hostPath:
              path: /mnt/catcat_data/model
          - name: shm-volume
            emptyDir:
              sizeLimit: 512Gi
              medium: Memory
          - name: localtime
            hostPath:
              path: /etc/localtime
              type: File
        schedulerName: volcano
    workerTemplate:
      metadata:
        name: sglang-worker
      spec:
        containers:
          - name: sglang-worker
            image: lmsysorg/sglang:v0.4.3.post2-cu124
            imagePullPolicy: IfNotPresent
            workingDir: /sgl-workspace
            command: ["sh", "-c"]
            args:
            - >
              cd /sgl-workspace && python3 -m sglang.launch_server
              --model-path /mnt/catcat_data/model/DeepSeek-R1
              --served-model-name deepseek-r1
              --tp 16
              --dist-init-addr $LWS_LEADER_ADDRESS:20000
              --nnodes $LWS_GROUP_SIZE
              --node-rank $LWS_WORKER_INDEX
              --trust-remote-code
              --context-length 131072
              --enable-metrics
              --host 0.0.0.0
              --port 8000
            env:
              - name: GLOO_SOCKET_IFNAME
                value: eth0
              - name: NCCL_IB_HCA
                value: "mlx5_0,mlx5_1,mlx5_4,mlx5_5"
              - name: NCCL_P2P_LEVEL
                value: "NVL"
              - name: NCCL_IB_GID_INDEX
                value: "0"
              - name: NCCL_IB_CUDA_SUPPORT
                value: "1"
              - name: NCCL_IB_DISABLE
                value: "0"
              - name: NCCL_SOCKET_IFNAME
                value: "eth0"
              - name: NCCL_DEBUG
                value: "INFO"
              - name: NCCL_NET_GDR_LEVEL
                value: "2"
              - name: SGLANG_USE_MODELSCOPE
                value: "true"
              - name: LWS_WORKER_INDEX
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.labels['leaderworkerset.sigs.k8s.io/worker-index']
            ports:
            - containerPort: 8000
              name: http
              protocol: TCP
            - containerPort: 20000
              name: distributed
              protocol: TCP
            resources:
              limits:
                cpu: "128"
                memory: "1Ti"
                nvidia.com/gpu: "8"
                rdma/ib: "4"
              requests:
                cpu: "128"
                memory: "1Ti"
                nvidia.com/gpu: "8"
                rdma/ib: "4"
            securityContext:
              capabilities:
                add:
                - IPC_LOCK
                - SYS_PTRACE
            volumeMounts:
              - mountPath: /mnt/catcat_data/model
                name: model-volume
              - mountPath: /dev/shm
                name: shm-volume
              - name: localtime
                mountPath: /etc/localtime
                readOnly: true
        volumes:
          - name: model-volume
            hostPath:
              path: /mnt/catcat_data/model
          - name: shm-volume
            emptyDir:
              sizeLimit: 512Gi
              medium: Memory
          - name: localtime
            hostPath:
              path: /etc/localtime
              type: File
        schedulerName: volcano
```

```shell
kubectl apply -f deepseek-r1-lws-sglang.yaml

kubectl get lws -n deepseek
NAME     AGE
sglang   1h

kubectl get pods -n deepseek |grep sglang
sglang-0                                 1/1     Running   0          2h
sglang-0-1                               1/1     Running   0         2h
```

```shell
##æŸ¥çœ‹æ—¥å¿—
~# kubectl logs -n deepseek sglang-0
[2025-02-16 12:25:49] server_args=ServerArgs(model_path='deepseek-ai/DeepSeek-R1', tokenizer_path='deepseek-ai/DeepSeek-R1', tokenizer_mode='auto', load_format='auto', trust_remote_code=True, dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, quantization=None, context_length=None, device='cuda', served_model_name='deepseek-ai/DeepSeek-R1', chat_template=None, is_embedding=False, revision=None, skip_tokenizer_init=False, host='0.0.0.0', port=30000, mem_fraction_static=0.81, max_running_requests=None, max_total_tokens=None, chunked_prefill_size=4096, max_prefill_tokens=16384, schedule_policy='lpm', schedule_conservativeness=0.3, cpu_offload_gb=0, prefill_only_one_req=False, tp_size=8, stream_interval=1, stream_output=False, random_seed=773491082, constrained_json_whitespace_pattern=None, watchdog_timeout=300, download_dir=None, base_gpu_id=0, log_level='info', log_level_http=None, log_requests=False, show_time_cost=False, enable_metrics=False, decode_log_interval=40, api_key=None, file_storage_pth='sglang_storage', enable_cache_report=False, dp_size=8, load_balance_method='round_robin', ep_size=1, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', lora_paths=None, max_loras_per_batch=8, lora_backend='triton', attention_backend='flashinfer', sampling_backend='flashinfer', grammar_backend='outlines', speculative_draft_model_path=None, speculative_algorithm=None, speculative_num_steps=5, speculative_num_draft_tokens=64, speculative_eagle_topk=8, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, disable_radix_cache=False, disable_jump_forward=False, disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_nccl_nvls=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, disable_mla=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_ep_moe=False, enable_torch_compile=False, torch_compile_max_bs=32, cuda_graph_max_bs=160, cuda_graph_bs=None, torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, allow_auto_truncate=False, return_hidden_states=False, enable_custom_logit_processor=False, tool_call_parser=None, enable_hierarchical_cache=False, enable_flashinfer_mla=False)
Downloading Model to directory: /root/.cache/modelscope/hub/deepseek-ai/DeepSeek-R1
Downloading Model to directory: /root/.cache/modelscope/hub/deepseek-ai/DeepSeek-R1
INFO 02-16 12:25:53 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:25:53 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
INFO 02-16 12:26:01 __init__.py:190] Automatically detected platform cuda.
```

### æŸ¥çœ‹æ˜¾å­˜å ç”¨

<picture>
    <source srcset="https://s3.catcat.blog/images/2025/02/image-12.avif" type="image/avif">
    <source srcset="https://s3.catcat.blog/images/2025/02/image-12.webp" type="image/webp">
    <img src="https://s3.catcat.blog/images/2025/02/image-12.jpg" alt="" loading="lazy">
</picture>

### æœåŠ¡è®¿é—®

ç¼–å†™SVC

```shell
apiVersion: v1
kind: Service
metadata:
  name: sglang-api-svc 
  labels:
    app: sglang
spec:
  selector:
      leaderworkerset.sigs.k8s.io/name: sglang
      role: leader
  ports:
    - protocol: TCP
      port: 8000
      targetPort: http
      name: http
  type: NodePort      
```

éƒ¨ç½²SVC

kubectl applyÂ -f deepseek-r1-svc.yamlÂ -n deepseek

### Curl æµ‹è¯•éƒ¨ç½²

```shell
curl -X POST http://ip:port/v1/chat/completions -H "Content-Type: application/json" -d '{
    "model": "/model",
    "messages": [
        {
            "role": "user",
            "content": "ä½ æ˜¯ä»€ä¹ˆæ¨¡å‹"
        }
    ],
    "stream": false,
    "temperature": 0.8
}'
```

## éƒ¨ç½²OpenwebUI

è¿™é‡Œç»™å‡ºyamlï¼Œä¸åœ¨è¿‡å¤šèµ˜è¿°äº†

```shell
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: open-webui-data-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
  storageClassName: nfs-client

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-webui-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: open-webui
  template:
    metadata:
      labels:
        app: open-webui
    spec:
      containers:
      - name: open-webui
        image: ghcr.sakiko.de/open-webui/open-webui:main
        imagePullPolicy: Always
        ports:
        - containerPort: 8080
        env:
        - name: OPENAI_API_BASE_URL
          value: "http://ip:port/v1"   # æ›¿æ¢ä¸ºSGLang API
        - name: ENABLE_OLLAMA_API # ç¦ç”¨ Ollama APIï¼Œåªä¿ç•™ OpenAI API
          value: "False"
        volumeMounts:
        - name: open-webui-data
          mountPath: /app/backend/data
      volumes:
      - name: open-webui-data
        persistentVolumeClaim:
          claimName: open-webui-data-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: open-webui-service
spec:
  type: ClusterIP
  ports:
    - port: 3000
      targetPort: 8080 
  selector:
    app: open-webui
```

<picture>
    <source srcset="https://s3.catcat.blog/images/2025/02/image-13.avif" type="image/avif">
    <source srcset="https://s3.catcat.blog/images/2025/02/image-13.webp" type="image/webp">
    <img src="https://s3.catcat.blog/images/2025/02/image-13.jpg" alt="" loading="lazy">
</picture>
